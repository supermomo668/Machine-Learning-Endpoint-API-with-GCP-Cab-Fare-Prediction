{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "source": [
    "# Machine Learning Project, Task 1: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-74.25909, 40.477399, -73.7001809, 40.9161785)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "import osmnx as ox\n",
    "from shapely.geometry import Point\n",
    "gdf = ox.geocode_to_gdf('New York, NY, USA')\n",
    "geom = gdf.loc[0, 'geometry']\n",
    "\n",
    "# get the bounding box of the city\n",
    "geom.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-02-03 20:51:29.0000003</th>\n",
       "      <td>12.9</td>\n",
       "      <td>2010-02-03 20:51:29+00:00</td>\n",
       "      <td>-73.954191</td>\n",
       "      <td>40.764029</td>\n",
       "      <td>-73.918043</td>\n",
       "      <td>40.766876</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-09 13:42:00.00000036</th>\n",
       "      <td>14.5</td>\n",
       "      <td>2013-06-09 13:42:00+00:00</td>\n",
       "      <td>-74.004507</td>\n",
       "      <td>40.741932</td>\n",
       "      <td>-74.005212</td>\n",
       "      <td>40.705272</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              fare_amount           pickup_datetime  \\\n",
       "key                                                                   \n",
       "2010-02-03 20:51:29.0000003          12.9 2010-02-03 20:51:29+00:00   \n",
       "2013-06-09 13:42:00.00000036         14.5 2013-06-09 13:42:00+00:00   \n",
       "\n",
       "                              pickup_longitude  pickup_latitude  \\\n",
       "key                                                               \n",
       "2010-02-03 20:51:29.0000003         -73.954191        40.764029   \n",
       "2013-06-09 13:42:00.00000036        -74.004507        40.741932   \n",
       "\n",
       "                              dropoff_longitude  dropoff_latitude  \\\n",
       "key                                                                 \n",
       "2010-02-03 20:51:29.0000003          -73.918043         40.766876   \n",
       "2013-06-09 13:42:00.00000036         -74.005212         40.705272   \n",
       "\n",
       "                              passenger_count  \n",
       "key                                            \n",
       "2010-02-03 20:51:29.0000003                 1  \n",
       "2013-06-09 13:42:00.00000036                1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/cc_nyc_fare_train_tiny.csv', parse_dates=['pickup_datetime'], index_col=0)\n",
    "#data = df_to_geojson(df, lat='pickup_latitude', lon='pickup_longitude')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "source": [
    "## Utility Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(origin, destination):\n",
    "    \"\"\"\n",
    "    # Formula to calculate the spherical distance between 2 coordinates, with each specified as a (lat, lng) tuple\n",
    "\n",
    "    :param origin: (lat, lng)\n",
    "    :type origin: tuple\n",
    "    :param destination: (lat, lng)\n",
    "    :type destination: tuple\n",
    "    :return: haversine distance\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    lat1, lon1 = origin\n",
    "    lat2, lon2 = destination\n",
    "    radius = 6371  # km\n",
    "\n",
    "    dlat = math.radians(lat2 - lat1)\n",
    "    dlon = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dlat / 2) * math.sin(dlat / 2) + math.cos(math.radians(lat1)) * math.cos(\n",
    "        math.radians(lat2)) * math.sin(dlon / 2) * math.sin(dlon / 2)\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    d = radius * c\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "source": [
    "## Feature Engineering\n",
    "> TODO: You need to implement the two functions below to take in raw data, perform data preprocessing and create new features using your knowledge of the problem domain. The main difference between processing test and training data is that **you cannot filter out records from the test set** (i.e., you have to return a prediction even if the input data may be an outlier).\n",
    "\n",
    "> Feel free to add additional cells to explore the data. You will also find it very helpful to visualize the distribution of the dataset to get a sense of the trends or patterns. **However, you will want to exclude these cells when we export the notebook as an executable.** The submitter will exclude any cells tagged with `excluded_from_script`, so make sure you tag any cells containing exploration code appropriately. You can display the tags for each cell as such: `View > Cell Toolbar > Tags`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datetime_tomore(df):\n",
    "    time_features = df.loc[:, ['pickup_datetime']]\n",
    "    # TODO: extract time-related features from the `pickup_datetime` column.\n",
    "    #       (replace \"None\" with your implementation)\n",
    "    time_features['year'] = time_features.pickup_datetime.apply(lambda x:x.year)\n",
    "    time_features['month'] = time_features.pickup_datetime.apply(lambda x:x.month)\n",
    "    time_features['hour'] = time_features.pickup_datetime.apply(lambda x:x.hour)\n",
    "    time_features['weekday'] = time_features.pickup_datetime.apply(lambda x:x.weekday)\n",
    "    # quantize\n",
    "    #time_features['hour_bin'] = pd.qcut(time_features['hour'],4).cat.codes\n",
    "    return pd.concat([df, time_features], axis=1)\n",
    "\n",
    "def filter_NYC(df):    \n",
    "    # determine if a point is within the city boundary\n",
    "    coord_list = list(df[['pickup_longitude','pickup_latitude']].to_records(index=False))\n",
    "    return df[[geom.intersects(Point(coords)) for coords in coord_list]]\n",
    "\n",
    "def process_distance(df):\n",
    "    pick_up_loc = [\"pickup_longitude\",\"pickup_latitude\"]\n",
    "    drop_off_loc = [\"dropoff_longitude\",\"dropoff_latitude\"]\n",
    "    return df.apply(lambda x: haversine_distance((x[pick_up_loc]), (x[drop_off_loc])), axis=1)\n",
    "\n",
    "def MSG_distance(df, mode=\"dropoff\"):\n",
    "    MSG_coor = (40.750298, -73.993324) # lat, lng\n",
    "    MSG_lat, MSG_long = MSG_coor\n",
    "    drop_off_loc = [\"dropoff_latitude\", \"dropoff_longitude\"]\n",
    "    pick_up_loc = [\"pickup_latitude\",\"pickup_longitude\"]\n",
    "    if mode==\"dropoff\":\n",
    "        return df.apply(lambda x: haversine_distance(MSG_coor, (x[drop_off_loc])), axis=1)\n",
    "    else:\n",
    "        return df.apply(lambda x: haversine_distance(MSG_coor, (x[pick_up_loc])), axis=1)\n",
    "\n",
    "fare_high = df[['fare_amount']].quantile(0.999)[0]\n",
    "fare_low = df[['fare_amount']].quantile(0.001)[0]\n",
    "def drop_quantile(df):\n",
    "    return df.loc[df.fare_amount > fare_low].loc[df.fare_amount < fare_high]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\"pickup_longitude\",\"pickup_latitude\",\"dropoff_longitude\",\"dropoff_latitude\",\"passenger_count\"]\n",
    "pred_col = ['fare_amount']\n",
    "\n",
    "def process_train_data(raw_df):\n",
    "    \"\"\"\n",
    "    TODO: Implement this method.\n",
    "    \n",
    "    You may drop rows if needed.\n",
    "\n",
    "    :param raw_df: the DataFrame of the raw training data\n",
    "    :return:  a DataFrame with the predictors created\n",
    "    \"\"\"\n",
    "    #fil na\n",
    "    raw_df[num_cols] = raw_df[num_cols].fillna(value=raw_df[num_cols].mean())\n",
    "    # drop location\n",
    "    raw_df = filter_NYC(raw_df)\n",
    "    #raw_df[num_cols] = raw_df[num_cols].fillna(value=raw_df[num_cols].mean())\n",
    "    # filter quantile\n",
    "    raw_df = drop_quantile(raw_df)\n",
    "    # datetime\n",
    "    raw_df = datetime_tomore(raw_df)\n",
    "    # distance\n",
    "    raw_df[\"distance\"] = process_distance(raw_df)\n",
    "    #raw_df = raw_df.drop(num_cols[:-1], axis=1)\n",
    "    return raw_df\n",
    "\n",
    "\n",
    "def process_test_data(raw_df):\n",
    "    \"\"\"\n",
    "    TODO: Implement this method.\n",
    "    \n",
    "    You should NOT drop any rows.\n",
    "\n",
    "    :param raw_df: the DataFrame of the raw test data\n",
    "    :return: a DataFrame with the predictors created\n",
    "    \"\"\"\n",
    "    # fill mean\n",
    "    raw_df[num_cols] = raw_df[num_cols].fillna(value=raw_df[num_cols].mean())\n",
    "    # \n",
    "    # datetime\n",
    "    raw_df = datetime_tomore(raw_df)\n",
    "    # distance\n",
    "    raw_df[\"distance\"] = process_distance(raw_df)\n",
    "    #raw_df = raw_df.drop(num_cols[:-1], axis=1)\n",
    "    return raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "source": [
    "## Model Checking with XGBoost and k-fold Cross Validation\n",
    "> As you iterate on your features, you want to quickly validate the model and evaluate if these new features help to improve your model's predictions. This process is known as model checking. You will use XGBoost to train the model, and use Root Mean Squared Error (RMSE) to quantify the performance. Cross validation is used to evaluate how the performance of the model will generalize to an unseen dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the raw data: (110222, 8)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "raw_train = pd.read_csv('data/cc_nyc_fare_train_tiny.csv', parse_dates=['pickup_datetime'])\n",
    "print('Shape of the raw data: {}'.format(raw_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine threshold\n",
    "fare_high = df[['fare_amount']].quantile(0.999)[0]\n",
    "fare_low = df[['fare_amount']].quantile(0.001)[0]\n",
    "def drop_quantile(df):\n",
    "    return df.loc[df.fare_amount > fare_low].loc[df.fare_amount < fare_high]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the feature matrix: (71731, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-02-03 20:51:29.0000003</td>\n",
       "      <td>12.9</td>\n",
       "      <td>2010-02-03 20:51:29+00:00</td>\n",
       "      <td>-73.954191</td>\n",
       "      <td>40.764029</td>\n",
       "      <td>-73.918043</td>\n",
       "      <td>40.766876</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-03 20:51:29+00:00</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>4.020429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-06-09 13:42:00.00000036</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2013-06-09 13:42:00+00:00</td>\n",
       "      <td>-74.004507</td>\n",
       "      <td>40.741932</td>\n",
       "      <td>-74.005212</td>\n",
       "      <td>40.705272</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-06-09 13:42:00+00:00</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>1.126010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            key  fare_amount           pickup_datetime  \\\n",
       "0   2010-02-03 20:51:29.0000003         12.9 2010-02-03 20:51:29+00:00   \n",
       "1  2013-06-09 13:42:00.00000036         14.5 2013-06-09 13:42:00+00:00   \n",
       "\n",
       "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
       "0        -73.954191        40.764029         -73.918043         40.766876   \n",
       "1        -74.004507        40.741932         -74.005212         40.705272   \n",
       "\n",
       "   passenger_count           pickup_datetime  year  month  hour  weekday  \\\n",
       "0                1 2010-02-03 20:51:29+00:00  2010      2    20        2   \n",
       "1                1 2013-06-09 13:42:00+00:00  2013      6    13        6   \n",
       "\n",
       "   distance  \n",
       "0  4.020429  \n",
       "1  1.126010  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform features using the function you have defined\n",
    "df_train = process_train_data(raw_train)\n",
    "\n",
    "# Remove fields that we do not want to train with\n",
    "X = df_train.drop(['key', 'fare_amount', 'pickup_datetime'], axis=1, errors='ignore')\n",
    "\n",
    "# Extract the value you want to predict\n",
    "Y = df_train['fare_amount']\n",
    "print('Shape of the feature matrix: {}'.format(X.shape))\n",
    "\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE with 5-fold Cross Validation: 4.147\n"
     ]
    }
   ],
   "source": [
    "# Evaluate features with K-fold cross validation\n",
    "# The higher K is, the longer it takes to run, and the higher your confidence in the score\n",
    "K = 5\n",
    "model = XGBRegressor(objective ='reg:squarederror')\n",
    "scores = cross_val_score(model, X, Y, cv=K, scoring='neg_mean_squared_error', verbose=False)\n",
    "avg_rmse = math.sqrt(abs(np.mean(scores)))\n",
    "\n",
    "print('Average RMSE with {}-fold Cross Validation: {:.3f}'.format(K, avg_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "source": [
    "## Evaluating Feature Importance\n",
    "> After you train the model, XGBoost has a handy utility that allows you to compare the relative importance of each feature. You should use this to assess which features you created are meaningful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "             importance_type=None, interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, ...)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model again with the entire training set\n",
    "model = XGBRegressor(objective ='reg:squarederror')\n",
    "model.fit(X, Y)\n",
    "#xgb.plot_importance(model, height=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "source": [
    "## Evaluating against Hidden Test Set\n",
    "> Once you are satisfied with the performance of the features you have selected, you can use the trained model to make predictions on the hidden test set. **Do not change the default configuration of the model.** In task 1, you want to focus on feature selection, without worrying about tuning the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build final model with the entire training set\n",
    "final_model = XGBRegressor(objective ='reg:squarederror')\n",
    "final_model.fit(X, Y)\n",
    "\n",
    "# Read and transform test set\n",
    "raw_test = pd.read_csv('data/cc_nyc_fare_test.csv', parse_dates=['pickup_datetime'])\n",
    "df_test = process_test_data(raw_test)\n",
    "X_test = df_test.drop(['key', 'pickup_datetime'], axis=1, errors='ignore')\n",
    "\n",
    "# Make predictions for test set and output a csv file\n",
    "# DO NOT change the column names\n",
    "df_test['predicted_fare_amount'] = final_model.predict(X_test)\n",
    "df_test[['key', 'predicted_fare_amount']].to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
